{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Masking\n",
    "from tqdm import tqdm_notebook\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.utils import to_categorical\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 673194290245745449\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6700998385222685573\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6685550442572346285\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5811535872\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7956821867374047407\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_가전제품 = pd.read_csv('Y_가전제품.csv')\n",
    "Y_화장품 = pd.read_csv('Y_화장품.csv')\n",
    "Y_패션 = pd.read_csv('Y_패션.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_가전제품= Y_가전제품['가전제품구매']\n",
    "Y_화장품= Y_화장품['화장품구매']\n",
    "Y_패션= Y_패션['패션구매']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_가전제품 = pd.read_csv('가전제품_3d_array.csv')\n",
    "X_화장품 = pd.read_csv('화장품_3d_array.csv')\n",
    "X_패션 = pd.read_csv('패션_3d_array.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>94990</th>\n",
       "      <th>94991</th>\n",
       "      <th>94992</th>\n",
       "      <th>94993</th>\n",
       "      <th>94994</th>\n",
       "      <th>94995</th>\n",
       "      <th>94996</th>\n",
       "      <th>94997</th>\n",
       "      <th>94998</th>\n",
       "      <th>94999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1754</td>\n",
       "      <td>29010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308</td>\n",
       "      <td>10185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>29956</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1361</td>\n",
       "      <td>7985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1  2  3  4  5  6  7  8  9  ...  94990  94991  94992  94993  \\\n",
       "0  1754  29010  0  0  0  0  1  0  0  0  ...      0      0      0      0   \n",
       "1   308  10185  0  0  0  0  1  0  0  0  ...      0      0      0      0   \n",
       "2    24    314  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "3  1302  29956  0  0  0  0  0  0  0  1  ...      0      0      0      0   \n",
       "4  1361   7985  0  0  0  0  0  0  0  1  ...      0      0      0      0   \n",
       "\n",
       "   94994  94995  94996  94997  94998  94999  \n",
       "0      0      0      0      0      1      0  \n",
       "1      0      0      0      0      1      0  \n",
       "2      0      0      0      0      1      0  \n",
       "3      0      0      1      0      0      0  \n",
       "4      0      0      0      0      1      0  \n",
       "\n",
       "[5 rows x 95000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_가전제품.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_가전제품 = np.asarray(X_가전제품)\n",
    "X_화장품 = np.asarray(X_화장품)\n",
    "X_패션 = np.asarray(X_패션)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1063, 95000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_가전제품.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5000일때 자꾸 커널이 죽음\n",
    "def oversample(X, Y):\n",
    "    max_len = 5000\n",
    "    X_resampled, Y_resampled = smote.fit_resample(X, Y)\n",
    "    X_resampled = X_resampled.reshape(X_resampled.shape[0], max_len, int(X_resampled.shape[1]/max_len))\n",
    "    return X_resampled, Y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_가전제품_resampled, Y_가전제품_resampled =oversample(X_가전제품, Y_가전제품)\n",
    "X_패션_resampled, Y_패션_resampled = oversample(X_패션, Y_패션)\n",
    "X_화장품_resampled, Y_화장품_resampled = oversample(X_화장품, Y_화장품)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 가동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 패션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_패션_resampled, Y_패션_resampled, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1606, 5000, 19)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0120 15:56:23.525620 140037974812480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, 5000, 19)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                21504     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 24,163\n",
      "Trainable params: 24,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0120 15:56:25.005447 140037974812480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1606 samples, validate on 689 samples\n",
      "Epoch 1/30\n",
      " - 98s - loss: 1.0741 - acc: 0.4166 - val_loss: 1.0368 - val_acc: 0.5254\n",
      "Epoch 2/30\n",
      " - 98s - loss: 1.0148 - acc: 0.5430 - val_loss: 0.9806 - val_acc: 0.5544\n",
      "Epoch 3/30\n",
      " - 98s - loss: 0.9538 - acc: 0.5560 - val_loss: 0.9207 - val_acc: 0.5472\n",
      "Epoch 4/30\n",
      " - 98s - loss: 0.9106 - acc: 0.5585 - val_loss: 0.8915 - val_acc: 0.5443\n",
      "Epoch 5/30\n",
      " - 98s - loss: 0.8750 - acc: 0.5716 - val_loss: 0.8587 - val_acc: 0.5660\n",
      "Epoch 6/30\n",
      " - 98s - loss: 0.8497 - acc: 0.5909 - val_loss: 0.8367 - val_acc: 0.5951\n",
      "Epoch 7/30\n",
      " - 98s - loss: 0.8354 - acc: 0.5978 - val_loss: 0.8297 - val_acc: 0.5980\n",
      "Epoch 8/30\n",
      " - 98s - loss: 0.8230 - acc: 0.6052 - val_loss: 0.8188 - val_acc: 0.6154\n",
      "Epoch 9/30\n",
      " - 98s - loss: 0.8102 - acc: 0.6146 - val_loss: 0.8236 - val_acc: 0.6125\n",
      "Epoch 10/30\n",
      " - 98s - loss: 0.8047 - acc: 0.6096 - val_loss: 0.8084 - val_acc: 0.6168\n",
      "Epoch 11/30\n",
      " - 99s - loss: 0.7946 - acc: 0.6208 - val_loss: 0.8295 - val_acc: 0.6096\n",
      "Epoch 12/30\n",
      " - 98s - loss: 0.7881 - acc: 0.6245 - val_loss: 0.8515 - val_acc: 0.5994\n",
      "Epoch 13/30\n",
      " - 98s - loss: 0.7821 - acc: 0.6320 - val_loss: 0.8438 - val_acc: 0.5965\n",
      "Epoch 14/30\n",
      " - 98s - loss: 0.7743 - acc: 0.6370 - val_loss: 0.8467 - val_acc: 0.6067\n",
      "Epoch 15/30\n",
      " - 98s - loss: 0.7731 - acc: 0.6413 - val_loss: 0.8222 - val_acc: 0.6226\n",
      "Epoch 16/30\n",
      " - 97s - loss: 0.7635 - acc: 0.6451 - val_loss: 0.8207 - val_acc: 0.6168\n",
      "Epoch 17/30\n",
      " - 98s - loss: 0.7573 - acc: 0.6526 - val_loss: 0.8669 - val_acc: 0.6096\n",
      "Epoch 18/30\n",
      " - 98s - loss: 0.7572 - acc: 0.6432 - val_loss: 0.8165 - val_acc: 0.6096\n",
      "Epoch 19/30\n",
      " - 99s - loss: 0.7501 - acc: 0.6476 - val_loss: 0.8300 - val_acc: 0.6052\n",
      "Epoch 20/30\n",
      " - 98s - loss: 0.7486 - acc: 0.6494 - val_loss: 0.8211 - val_acc: 0.6096\n",
      "Epoch 21/30\n",
      " - 99s - loss: 0.7407 - acc: 0.6563 - val_loss: 0.8929 - val_acc: 0.5878\n",
      "Epoch 22/30\n",
      " - 99s - loss: 0.7387 - acc: 0.6526 - val_loss: 0.8048 - val_acc: 0.6183\n",
      "Epoch 23/30\n",
      " - 99s - loss: 0.7292 - acc: 0.6625 - val_loss: 0.8294 - val_acc: 0.6067\n",
      "Epoch 24/30\n",
      " - 98s - loss: 0.7304 - acc: 0.6594 - val_loss: 0.8214 - val_acc: 0.6067\n",
      "Epoch 25/30\n",
      " - 98s - loss: 0.7359 - acc: 0.6445 - val_loss: 0.8169 - val_acc: 0.6038\n",
      "Epoch 26/30\n",
      " - 98s - loss: 0.7225 - acc: 0.6700 - val_loss: 0.8033 - val_acc: 0.6154\n",
      "Epoch 27/30\n",
      " - 98s - loss: 0.7201 - acc: 0.6712 - val_loss: 0.8136 - val_acc: 0.6197\n",
      "Epoch 28/30\n",
      " - 98s - loss: 0.7085 - acc: 0.6812 - val_loss: 0.8051 - val_acc: 0.6197\n",
      "Epoch 29/30\n",
      " - 99s - loss: 0.7097 - acc: 0.6663 - val_loss: 0.8061 - val_acc: 0.6139\n",
      "Epoch 30/30\n",
      " - 98s - loss: 0.6966 - acc: 0.6756 - val_loss: 0.8176 - val_acc: 0.6154\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=100, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perm = PermutationImportance(model, random_state=1).fit(X_test,y_test)\n",
    "#eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846383094788\n"
     ]
    }
   ],
   "source": [
    "#가전제품 f1-score: 0.7819220343082984\n",
    "#패션 accuracy: 0.7188029361269287\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가전제품"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_가전제품_resampled, Y_가전제품_resampled, test_size=0.3, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_2 (Masking)          (None, 5000, 19)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                21504     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 24,163\n",
      "Trainable params: 24,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1946 samples, validate on 835 samples\n",
      "Epoch 1/30\n",
      " - 30s - loss: 1.0938 - acc: 0.3510 - val_loss: 1.0553 - val_acc: 0.4311\n",
      "Epoch 2/30\n",
      " - 29s - loss: 1.0380 - acc: 0.4959 - val_loss: 1.0181 - val_acc: 0.5102\n",
      "Epoch 3/30\n",
      " - 28s - loss: 0.9959 - acc: 0.5591 - val_loss: 0.9789 - val_acc: 0.5269\n",
      "Epoch 4/30\n",
      " - 29s - loss: 0.9479 - acc: 0.5910 - val_loss: 0.9385 - val_acc: 0.5353\n",
      "Epoch 5/30\n",
      " - 29s - loss: 0.8881 - acc: 0.6048 - val_loss: 0.8840 - val_acc: 0.5653\n",
      "Epoch 6/30\n",
      " - 29s - loss: 0.8390 - acc: 0.6238 - val_loss: 0.8510 - val_acc: 0.5713\n",
      "Epoch 7/30\n",
      " - 29s - loss: 0.8076 - acc: 0.6429 - val_loss: 0.8196 - val_acc: 0.5988\n",
      "Epoch 8/30\n",
      " - 29s - loss: 0.7747 - acc: 0.6588 - val_loss: 0.7935 - val_acc: 0.6132\n",
      "Epoch 9/30\n",
      " - 30s - loss: 0.7495 - acc: 0.6706 - val_loss: 0.7859 - val_acc: 0.6048\n",
      "Epoch 10/30\n",
      " - 29s - loss: 0.7486 - acc: 0.6511 - val_loss: 0.7672 - val_acc: 0.6144\n",
      "Epoch 11/30\n",
      " - 29s - loss: 0.7181 - acc: 0.6727 - val_loss: 0.7497 - val_acc: 0.6395\n",
      "Epoch 12/30\n",
      " - 29s - loss: 0.7020 - acc: 0.6906 - val_loss: 0.7332 - val_acc: 0.6599\n",
      "Epoch 13/30\n",
      " - 30s - loss: 0.6863 - acc: 0.6999 - val_loss: 0.7255 - val_acc: 0.6611\n",
      "Epoch 14/30\n",
      " - 29s - loss: 0.6986 - acc: 0.6937 - val_loss: 0.7417 - val_acc: 0.6335\n",
      "Epoch 15/30\n",
      " - 29s - loss: 0.6723 - acc: 0.7091 - val_loss: 0.7140 - val_acc: 0.6695\n",
      "Epoch 16/30\n",
      " - 29s - loss: 0.6578 - acc: 0.7261 - val_loss: 0.7043 - val_acc: 0.6886\n",
      "Epoch 17/30\n",
      " - 29s - loss: 0.6511 - acc: 0.7271 - val_loss: 0.7017 - val_acc: 0.6731\n",
      "Epoch 18/30\n",
      " - 29s - loss: 0.6595 - acc: 0.7240 - val_loss: 0.7183 - val_acc: 0.6766\n",
      "Epoch 19/30\n",
      " - 29s - loss: 0.6454 - acc: 0.7276 - val_loss: 0.6968 - val_acc: 0.7030\n",
      "Epoch 20/30\n",
      " - 29s - loss: 0.6468 - acc: 0.7189 - val_loss: 0.7146 - val_acc: 0.6874\n",
      "Epoch 21/30\n",
      " - 29s - loss: 0.6645 - acc: 0.7107 - val_loss: 0.6969 - val_acc: 0.7054\n",
      "Epoch 22/30\n",
      " - 29s - loss: 0.6168 - acc: 0.7384 - val_loss: 0.6905 - val_acc: 0.7018\n",
      "Epoch 23/30\n",
      " - 29s - loss: 0.6162 - acc: 0.7369 - val_loss: 0.6875 - val_acc: 0.7042\n",
      "Epoch 24/30\n",
      " - 29s - loss: 0.6144 - acc: 0.7400 - val_loss: 0.6880 - val_acc: 0.7006\n",
      "Epoch 25/30\n",
      " - 29s - loss: 0.6072 - acc: 0.7436 - val_loss: 0.6818 - val_acc: 0.7030\n",
      "Epoch 26/30\n",
      " - 29s - loss: 0.6014 - acc: 0.7456 - val_loss: 0.6792 - val_acc: 0.7102\n",
      "Epoch 27/30\n",
      " - 30s - loss: 0.6345 - acc: 0.7359 - val_loss: 0.6795 - val_acc: 0.7186\n",
      "Epoch 28/30\n",
      " - 29s - loss: 0.5982 - acc: 0.7508 - val_loss: 0.6754 - val_acc: 0.7257\n",
      "Epoch 29/30\n",
      " - 29s - loss: 0.5856 - acc: 0.7590 - val_loss: 0.6715 - val_acc: 0.7162\n",
      "Epoch 30/30\n",
      " - 29s - loss: 0.5781 - acc: 0.7590 - val_loss: 0.6700 - val_acc: 0.7198\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=500, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3gU1f7H8ffJZtNDOjUEQu81dEEQUZqogFxRbFcE7OXqFb32n12velERULF3EUUpggjSS0B6DSGQhJJGQkjdJOf3x6wYSvomk918X8+zT3ZnZme/w+onkzNnzlFaa4QQQrgGN7MLEEII4TgS6kII4UIk1IUQwoVIqAshhAuRUBdCCBfibtYHh4aG6ubNm5v18UII4ZS2bNmSorUOK2m9aaHevHlzoqOjzfp4IYRwSkqpI6Wtl+YXIYRwIRLqQgjhQiTUhRDChZTZpq6UmguMBpK01p0usr4d8BHQA/iP1vp1h1cphBB2NpuNhIQEcnNzzS6lWnl5eREeHo7Vaq3Q+8pzofRj4B3g0xLWpwH3AddU6JOFEKISEhIS8Pf3p3nz5iilzC6nWmitSU1NJSEhgcjIyAq9t8zmF631KozgLml9ktZ6M2Cr0CcLIUQl5ObmEhIS4rKBDqCUIiQkpFJ/jdRom7pSaopSKlopFZ2cnFyTHy2EcCGuHOh/qewx1mioa63naK2jtNZRYWEl9p0vVVxKFs/+vBtbYZGDqxNCCOfndL1fDiWf4aO1ccz/M9HsUoQQdVB6ejozZ86s8PtGjhxJenp6NVR0LqcL9cva1adj43q8uyKGAjlbF0LUsJJCvaCgoNT3LVq0iMDAwOoq66wyQ10p9RWwHmirlEpQSt2ulJqmlJpmX99QKZUAPAQ8Yd+mXnUVrJTi3stacyQ1m593HKuujxFCiIuaPn06hw4dolu3bvTq1YuBAwcyZswYOnToAMA111xDz5496dixI3PmzDn7vubNm5OSkkJcXBzt27fnjjvuoGPHjlxxxRXk5OQ4rL4yuzRqrSeWsf4EEO6wisrhig4NaNfQn7d/j2FM1yZY3Fz/ookQ4kLP/rybPcdOO3SfHRrX4+mrOpa4/uWXX2bXrl1s27aNlStXMmrUKHbt2nW26+HcuXMJDg4mJyeHXr16MW7cOEJCQs7Zx8GDB/nqq694//33mTBhAvPmzWPSpEkOqd/pml8A3NwU91zWitjkLBbtPG52OUKIOqx3797n9CWfMWMGXbt2pW/fvsTHx3Pw4MEL3hMZGUm3bt0A6NmzJ3FxcQ6rx7RRGqtqRKdGtKp/kLd/P8iozo1wk7N1Ieqc0s6oa4qvr+/Z5ytXruS3335j/fr1+Pj4MHjw4Iv2Nff09Dz73GKxOLT5xSnP1AEsbop7hrTiwMkzLN1zwuxyhBB1hL+/P5mZmRddl5GRQVBQED4+Puzbt48NGzbUcHVOHOoAo7s0IjLUlxnLY9Bam12OEKIOCAkJYcCAAXTq1IlHHnnknHXDhw+noKCA9u3bM336dPr27Vvj9SmzwjAqKko7YpKM77ck8PB32/ng5igu79DAAZUJIWqzvXv30r59e7PLqBEXO1al1BatdVRJ73HqM3WAq7s1pmmwNzN+Pyhn60KIOs/pQ91qcePuwa3YkZDBHwdkPBkhRN3m9KEOMLZHOE0CvZmxXM7WhRB1m0uEuoe7G9MGt2Tr0XTWHUo1uxwhhDCNc4b6Rc7Gr+sZToN6nvxv+YUd/YUQoq5wvlA/sg7mXApZKecs9rJamHZpSzYdTmNDrJytCyHqJucLdU9/SNoH86dB0bmjNE7sHUGonydv/y5n60KI6lHZoXcB3nrrLbKzsx1c0bmcL9QbdoYrX4CYZbDh3H9YL6uFqYNasDYmlS1HSpyBTwghKk1CvTr0mgztRsNvz0DilnNW3dg3gmBfD2YsjzGnNiGESys+9O4jjzzCa6+9Rq9evejSpQtPP/00AFlZWYwaNYquXbvSqVMnvvnmG2bMmMGxY8cYMmQIQ4YMqbb6nHNAL6Xg6ndg1kD4/p8wdTV4GUO4+3i4M3lgJK8u2c+2+HS6Na3+QemFECZZPB1O7HTsPht2hhEvl7i6+NC7S5cu5fvvv2fTpk1orRkzZgyrVq0iOTmZxo0bs3DhQsAYEyYgIIA33niDFStWEBoa6tiai3HOM3UA7yAY9wGkx8MvD5zTI+bmfs0J8LbyjrStCyGq0dKlS1m6dCndu3enR48e7Nu3j4MHD9K5c2eWLVvGo48+yurVqwkICKixmpzzTP0vEX1hyOPw+/9BiyHQ4yYA/Dzduf2SSN5YdoBdiRl0alJz/6BCiBpUyhl1TdBa89hjjzF16tQL1m3dupVFixbxxBNPMHToUJ566qkaqcl5z9T/cslD0GIwLHrE6BVjd0v/5vh7ufPqr/vlLlMhhMMUH3r3yiuvZO7cuZw5cwaAxMREkpKSOHbsGD4+PkyaNIlHHnmErVu3XvDe6uL8oe7mBtfOAU8/+P42sBmDzQd4W3loWBtWHUhm/p+JJhcphHAVxYfeXbZsGTfccAP9+vWjc+fOjB8/nszMTHbu3Env3r3p1q0bzz77LE888QQAU6ZMYfjw4dV6odTph949K+Y3+HwcRP0TRr8JQGGRZsLs9RxKPsOyBy8lzN+zjJ0IIWo7GXrXxYfePavV5TDgfoieC7t/BIzZkV4Z15nsvEKeWbDb5AKFEKL6uU6oA1z2JDSJggX3wakjALSq78/9l7dm4c7jLNkl094JIVyba4W6xQrjPwQ0zLsdCm0ATBnUgg6N6vHkT7vIyLaZW6MQosrqQueHyh6ja4U6QFBzGDMDEjbDihcAYyKNV8d3IS0rn+cX7jG3PiFElXh5eZGamurSwa61JjU1FS8vrwq/17n7qZek47UQuxLWvAnNB0KroXRqEsDUQS2YufIQY7o1ZmDrMLOrFEJUQnh4OAkJCSQnu/ZMZ15eXoSHh1f4fa7T++V8thyYMwRy0uDO9eAbQq6tkJEzVpNnK2Lpg4Pw9XTN32lCCNdVd3q/nM/qDePeh5xT8Mv9oDVeVguvjuvCsYwcXvt1v9kVCiGEw7luqIMxMM9lT8Den2HblwBENQ/m5r7N+GR9HNFxMjyvEMK1uHaoA/S7B5pdAosfhVNxAPx7eDsaB3jz6Lwd5NoKza1PCCEcqMxQV0rNVUolKaV2lbBeKaVmKKVilFI7lFI9HF9mFbhZ4Nr3jOF6f5gKRYX4errz0tjOHErOklmShBAupTxn6h8Dw0tZPwJobX9MAd6relkOFhgBI1+H+A2w9i0ABrUJY3zPcGb9EcvuYxkmFyiEEI5RZqhrrVcBpTU+Xw18qg0bgEClVCNHFegwXSYYXR1XvAjHtgHwxKj2BPl48O/vd2ArLCpjB0IIUfs5ok29CRBf7HWCfdkFlFJTlFLRSqnoGu9jqhSMegN8w+CHKWDLIdDHg+ev6cjuY6d5f3VszdYjhBDVoEYvlGqt52ito7TWUWFhJtz84xMM18yElP2wzJhLcHinRozo1JC3fjtIXEpWzdckhBAO5IhQTwSaFnsdbl9WO7W8DPpMg02zIWY5AM+O6Yi7m+LFRXtNLk4IIarGEaG+ALjZ3gumL5ChtT7ugP1Wn8ufgbB28NPdkJ1G/Xpe3D2kFUv3nGRdTIrZ1QkhRKWVp0vjV8B6oK1SKkEpdbtSappSapp9k0VALBADvA/cVW3VOorVG8bOgawU+OVB0JrbL4mkSaA3z/2yh8Ii1x0oSAjh2srT+2Wi1rqR1tqqtQ7XWn+otZ6ltZ5lX6+11ndrrVtqrTtrratxQBcHatTVmLR6z4+w4xu8rBYeH9mefScy+TY6vuz3CyFELeT6d5SWZsD9ENHfmLQ6/SgjOzekV/MgXv91P6dzZdx1IYTzqduh7maBa2eB1jB/GkoX8dTojqRl5/PuihizqxNCiAqr26EOENQMRr4KR9bChpl0Dg9gXI9wPloTx5FU6eIohHAuEuoAXSdC21Gw/P8geT+PXNkWd4vipUX7zK5MCCEqREIdjLtNr3oLPHxh/lQa+Lpz1+CWLNl9gvWHUs2uTgghyk1C/S9+9WH0G3DsT1jzJpMHtqBJoDf/J10chRBOREK9uI7XQqdx8McreKXsZvqIduw5fprvt0gXRyGEc5BQP9/I140xYn68k9EdQ+jZLIjXfj1ApnRxFEI4AQn18/kEw1Uz4OQu1B+v8tToDqScyWPmykNmVyaEEGWSUL+YtsOh2yRY8wZdVQxjezThw9WHiU/LNrsyIYQolYR6SYa/CP6NYf40/j20GRY3xUuLZRRHIUTtJqFeEq8AuPodSD1Iw+jXuXNwSxbtPMHGWOniKISovSTUS9NyCPSaDOvfZWqzEzQO8JJRHIUQtZqEelkufxaCmuP5y908Pqwpu4+dZt6WBLOrEkKIi5JQL4unH1zzHqQfZdSJWXQND+DtFQcpkImqhRC1kIR6eTTrB/3uRkV/yBPtThCflsOS3SfMrkoIIS4goV5elz0JoW2J2vEUnUI0c1bForW0rQshahcJ9fKyesG176EyT/Bm8I/sSMhgQ2ya2VUJIcQ5JNQroklP6HU7rRLn09nnFLNXyV2mQojaRUK9oi55CKUsvBy2lJX7k9l/ItPsioQQ4iwJ9Yqq1wiibqND0i+0tqYwZ1Ws2RUJIcRZEuqVMeABlMXKK/WX8tO2RI5n5JhdkRBCABLqlVOvEfS8je5pi2nKST5aG2d2RUIIAUioV94lxtn6S6FL+HLjUU7LeOtCiFpAQr2y/BtC1D/pk7mMkPwEvtp41OyKhBBCQr1KBjyAsnjwXNBi5q49TH6BDB0ghDCXhHpV+DeAXrczKGc53plx/LQt0eyKhBB1nIR6VQ24Hyye/MdvIe+vjqVIhuUVQphIQr2q/Oqjet3O5baV2JIOsvJAktkVCSHqsHKFulJquFJqv1IqRik1/SLrmymlliuldiilViqlwh1fai024AFw9+RR7wXM/kNuRhJCmKfMUFdKWYB3gRFAB2CiUqrDeZu9Dnyqte4CPAe85OhCazW/MFTvyVxRtJrkuF1si083uyIhRB1VnjP13kCM1jpWa50PfA1cfd42HYDf7c9XXGS96+t/P8rqxUOePzJHBvoSQpikPKHeBIgv9jrBvqy47cBY+/NrAX+lVEjVy3MifmGoXpMZyToO7N7CkdQssysSQtRBjrpQ+jBwqVLqT+BSIBEoPH8jpdQUpVS0Uio6OTnZQR9diwy4H6xe3Of+Ix+sPmx2NUKIOqg8oZ4INC32Oty+7Cyt9TGt9VitdXfgP/ZlFzQsa63naK2jtNZRYWFhVSi7lvINxa33FEa7rWPLlg2knskzuyIhRB1TnlDfDLRWSkUqpTyA64EFxTdQSoUqpf7a12PAXMeW6UT63wfu3kzjez5df8TsaoQQdUyZoa61LgDuAX4F9gLfaq13K6WeU0qNsW82GNivlDoANABeqKZ6az/fENz6TmW0ZQNr1q0mO7/A7IqEEHWIMmvy5KioKB0dHW3KZ1e7rFQK3+zMorzOHB78DvcNbW12RUIIF6GU2qK1jippvdxRWh18Q7D0ncooy0a2/fEjSadzza5ICFFHSKhXl4EPURDchjfUm3zyy3KzqxFC1BES6tXF0x+PSd/g4e7O2H3/4sCR+LLfI4QQVSShXp2CIym87hMi3JLI/epWKJSLpkKI6iWhXs382w1hQ7vH6ZIbTcK3/zK7HCGEi5NQrwG9xz/Id+6jCd//MUXRn5hdjhDChUmo1wBPdwt+V73MH4Vd0Asfgri1ZpckhHBREuo1ZHiXcD5o+CTxuj76m0lwKs7skoQQLkhCvYYopXjwql7cmvcv8mwF8OX1kHva7LKEEC5GQr0G9YgIolPnHkzNuw+dcgB+uAOKLhjMUgghKk1CvYY9Orwd64s6Ma/B/XBgCSx/1uyShBAuREK9hjUN9uHWAc155EgUqR1uhrX/g21fmV2WEMJFSKib4O4hrQj0tvJA+j/QkZfCz/fB0Y1mlyWEcAES6iYI8LZy/9DWrI7NYFXX1yCgKXw9EVJlblMhRNVIqJvkxr7NiAz15bnlx7Fd/w1oDV9cB9lpZpcmhHBiEuomsVrcmD6iHYeSs/g61gMmfg0ZCfDVRLDJUL1CiMqRUDfRFR0a0DsymLeWHSCzfg8YOxviN8CP06CoyOzyhBBOSELdREopnhjVntSsfP679AB0vBaG/R/sng/LnzG7PCGEE3I3u4C6rkt4ILf2b87H6+JoVd+PSf3vhfQjRlfHwGbQ63azSxRCOBEJ9VrgiVHtOZqWzVM/7aJxoBeXDX8F0uNh0cMQEA5trjS7RCGEk5Dml1rA3eLG2xO706FxPe758k92Hs+C8XOhYWf47jY49qfZJQohnISEei3h6+nO3Ft6EeTjwT8/2UxijgVu+BZ8guHLf0D6UbNLFEI4AQn1WqR+PS8+uq0XubZCbvtoExnuIXDjd0YXxy+ug5x0s0sUQtRyEuq1TJsG/sye1JPDKVnc+fkW8oPbwj8+M+42/WYSFOSbXaIQohaTUK+F+rcK5eWxXVh3KJXpP+xARw6CMW9D3GpjnBjpwy6EKIH0fqmlxvUMJ+FUDm/+doCmQT48OGyi0a6+8kVwc4er/gduFrPLFELUMhLqtdh9Q1sRfyqb/y0/SHiQN9dd+m8ossGq18CWA9fOAovV7DKFELWIhHotppTipbGdOZGRy2M/7KRxoDcDLnsCrD7G5Bq2HLjuI3D3NLtUIUQtIW3qtZzV4sbMST1oVd+PaZ9tYf+JTBj4EIx4DfYvhK+uh/xss8sUQtQSEupOoJ6Xlbm39sLH08JtH20i6XQu9JkCV78LsSvh83EyibUQAihnqCulhiul9iulYpRS0y+yPkIptUIp9adSaodSaqTjS63bGgd6M/fWXqTn2Jjy2RZybYXQfRKM+wASNsGnV8tY7EKIskNdKWUB3gVGAB2AiUqpDudt9gTwrda6O3A9MNPRhQro2DiAN//RjW3x6UyftwOtNXQaB//4HE7ugo9Hw5kks8sUQpioPGfqvYEYrXWs1jof+Bq4+rxtNFDP/jwAOOa4EkVxV3ZsyCNXtuXHbceYudI+/V3bEcaQAqcOw0cjICPR3CKFEKYpT6g3AeKLvU6wLyvuGWCSUioBWATce7EdKaWmKKWilVLRycnJlShXANw1uCXXdGvMa7/u59fdJ4yFLYfApB+MM/WPhkPaYXOLFEKYwlEXSicCH2utw4GRwGdKqQv2rbWeo7WO0lpHhYWFOeij6x6lFC+P60LXpoE8+M029hyzXyRt1g9u/gnyMo0z9sOroLDA3GKFEDWqPKGeCDQt9jrcvqy424FvAbTW6wEvINQRBYqL87JaeP+mngR4W5n8yWaSM/OMFU16wK2LQBfBJ1fBq5Hw9Y0QPRdOHTG3aCFEtStPqG8GWiulIpVSHhgXQhect81RYCiAUqo9RqhL+0o1q1/Pi/dvjiItO5+pn0UbPWIAGnSAe6JhwqfGFHnHt8MvD8L/usCMHrDoEdi/BPLOmHsAQgiHU1rrsjcyuii+BViAuVrrF5RSzwHRWusF9t4w7wN+GBdN/621XlraPqOionR0dHSVD0DA4p3HufOLrYzt0YT/XtcVpdS5G2gNqTEQsxwOLYe4NWDLBjcrRPQ1ZlbqNRms3uYcgBCi3JRSW7TWUSWuL0+oVwcJdceasfwgbyw7wPQR7Zh2acvSNy7Ig6Mb4NDvRsif2AmhbY2xZJr0qJmChRCVUlaoyx2lLuLey1oxuksjXlmyj2V7Tpa+sbsntLgUhj0L09bATfONi6sfXA4rXoRCW80ULYRwOAl1F6GU4vXrutK5SQAPfP0n+05UYNiAlpfBXeuh83XwxyvwwVBI2lt9xQohqo2Eugvxslp4/+Yo/Lzcuf3jaFLO5JX/zd6BMHa2cXdqRiLMvhTWzoCiwuorWAjhcBLqLqaBvUdMypk8bv5w099dHcur/VVw1wZoPQyWPQkfj4K02OopVgjhcBLqLqhLeCBzbo7icEoW42et42hqBYfm9QszztivnQ0n98B7l8DmD41eNEKIWk1C3UVd2iaML+7oQ0aOjXGz1rH3eAWH5lUKul4Pd62Dpr1h4UPGEL8yrowQtZqEugvrERHEd1P7YVGKCbPXszmuEkPzBoQbvWNGvg5H18PMvsZZu0x+LUStJKHu4lo38Of7O/sR5ufJpA82snxvGd0dL0Yp6H0H3LkWGnc3zto/HgnJBxxfsBCiSiTU64DwIB++m9aPtg39mfLZFuZtSajcjoJbGAOGXT3T6PI4awD88SoU5Du2YCFEpUmo1xEhfp58eUdf+rYI5l/fbeeD1ZXs0aIUdL8R7tls9JRZ8QLMHgTxmx1bsBCiUiTU6xA/T3fm3tqLkZ0b8vzCvbyyZB+VHibCrz6Mn2tMzpGXCR8Og0X/Np4LIUwjoV7HeLpbeHtiD27oE8F7Kw/x2A87KSyqQlfFNlfC3Rug9xTYNAfe7QsHfnVcwUKICnE3uwBR8yxuiheu6USIrwdv/x5DYnoOPZsF4WW14OXuZvy0WvC0P/e02pe5W2jdwA+r5bxzAU9/GPmqMczAgnvhywnQcSwMfwn8G5pzkELUUTJKYx330drDvPbrfrLzyzccQI+IQL6Y3BdvD8vFNyjIh7VvwarXweIBQx43zuItcv4ghCPI0LuiXAqLNHkFheTaisi1FZJXYPw0HkXkFhQSm5zF8wv3MLRdfWZN6on7+WfsxaUegsWPQswyqN8RRr0OzfrX3AEJ4aLKCnU5fRKA0STj4+GOj0fJ2wxpCx7ubjz54y6e+HEXL43tfOGEHH8JaQk3fgf7FsKS6cacqV2uh2HPgX+D6jkIMOZk3fE1NOho9KkXoo6RUBcVclPfZiSdzuXt32OoX8+Lh4a1KXljpaD9aGNo39X/hXUzYP8iGPIfY6YlRzfJHF5l9MBJ3gtWX7jpB2NmJyHqEOn9IirsoWFtmBAVzozlB/l8Qzkms/bwgaFPwp3rITwKljwKcy6FI+sdU1B6PHx7izHRti0brpkF9RoZY9Uc3eiYzxDCSUioiwpTSvHitZ0Z2q4+T/20iyW7TpTvjaGtYNIPMOEzyEmHj4bD/DsrP7SvLde4o/WdXkY3yiH/gbs3QreJcMsv4NfACHa5MUrUIXKhVFRaTn4hN3ywgd3HTvPF5D70ah5c/jfnZxk9ZNa9DUU2CG4JrS43Hs0HgIdvye/V2mjGWfIYpB+BDtfAFc9DYNNztzt9zBgPPisFbvoRwntW7kCFqEWk94uoVmlZ+YyftY6UzDy+v7M/bRr4V2wH6Udh3yJjAuzDq6Egx+gK2ay/EfAth0L99kb7PEDKQaNXzaHlENYeRrxizLdakoxEY/Cx7FNw83xoIsEunJuEuqh28WnZjHtvHRY3xbw7+9M40LtyO7LlwtF1ELPceCTb50n1bwythoLVB6LnGj+HPA69bgeLtez9pscbZ+y56caAZNIrRjgxCXVRI/YcO80/Zq+nYYAX30/rT4BPOcK2LBkJ9oD/DWL/gLzT0H0SDH3amJ2pItKP2oP9tD3Yu1W9PiFMIKEuasy6QyncOnczXZsG8NntffCylnDXaWUUFkBuBviGVH4fp44YwZ6XCbcsgEZdHVefEDWkrFCX3i/CYfq3DOWNf3Ql+sgp7v3qT87kFThu5xb3qgU6QFAzuPUX8PCDT6+GEzsdU1tl2HJg/btG33ohHEhCXTjU6C6NeXp0B5btOcllr69k/p8JlR/etzoENTeC3eoDn4yBE7tqvoaDy4xpAX993Khh1WuOmx4w5xQU2hyzL+GUJNSFw906IJL5d/WnUYAXD36znfGz1rMrMcPssv4WHGkEu7sXfDTS6E2TsMXoKlmdMhLgm0nwxXhwsxpj0XcaB78/byzPrcK/UVEhrHsH/tseZvaDoxscV7dwKtKmLqpNUZHm+y0JvLJkH2nZ+VzfK4KHr2hDiJ+n2aUZ0mJh2dNwYAkU5ht95btMMIYQDmnpuM8ptMGGmbDyFdBFcOkj0O8ecPc0fpFsnAVLn4DAZvCPz6FBh4rtP2kv/HQ3JG4xuoCmHISMeGN0zKFPgaef445FmE4ulArTZeTYmLH8IB+vi8PXw8JDw9owqW+z0kd5rEk56bB3Aez4FuLWANroz955AnQaa8zyVFlxa2Hhv4zumW1GGP3qg5pduN2RdcZQB/ln4Op3jDP4shTkw5o3jeYbr3ow4lXjfflZ8Pv/wcbZEBAOV71l9PkXLsEhoa6UGg78D7AAH2itXz5v/ZvAEPtLH6C+1jqwtH1KqNc9B09m8szPu1kbk0rbBv48PaYD/VuGml3WuTISYdc8I+BP7gRlgRaDjTP4pn2MST+s5eiHfyYJlj0F27+CgAgjzNuNLP09p4/Dd7dA/EboezcMe7bkfviJW+CneyFpt/GXxfCXwfe8f8ujG4xJS1IOQNcb4MoXwKcCd/2KWqnKoa6UsgAHgGFAArAZmKi13lPC9vcC3bXW/yxtvxLqdZPWml93n+T5hXtIOJXDqM6NeHxUe5pU9oal6pS01wj3nd9DxtG/l3vWM8aV8WtgDCPs1+Dc1ykxsOJ5yM+GAffBwIeNQc3KoyAflv7HmBqw2SVw3Ufn/qWQnw0rXzR6zvg1hNFvQNsRJe/Plmucya99C7yDYOTr0PGayv17iFrBEaHeD3hGa32l/fVjAFrrl0rYfh3wtNZ6WWn7lVCv23JthcxZFcvMlTFoDVMvbcm0S1vg41H14Xj/+m+6xLHeK6qoCBKjjbbqMyeMs/BM+88zJyDzJNiyzn1P5CAY+V8IK2Vo4tJs/wZ+vh+8A40B0Jr2MoZR+Pk+41pAz1uNsem9Asq3v+M7YME9cHw7tBsNo/4rUw06KUeE+nhguNZ6sv31TUAfrfU9F9m2GbABCNdaXzA/mlJqCjAFICIioueRI+UYtlW4tMT0HF5evI+ftx+jYT0vpo9ox9XdGlcqkE9l5fP5hiN8uuEIvSODeXNCNzzca6jdPu8MnDlpPAAi+v09Xk1lndhp9IrJSDTaxA8shqBIGDPD+KVRUYUFsP4dWPmScZH2sieh/VUS7tY2MfYAABLESURBVE6mpkP9UYxAv7eswuRMXRS3OS6N537ew87EDHpEBPL0VR3p2rTUyzJnxaVk8eGaw3y3JZ5cWxHdIwL582g6g9uGMWtST8fe2VrTck7BD1OMoRL63mUML1zeppySpMQYZ/xH1hqvg5obv4Qi+ho/Q9tU/ReSqDY12vyilPoTuFtrva6swiTUxfmKijTfb03g1SX7STmTx7ge4fx7eFsa1PO6YFutNVuOnOL91bEs3XMSq5sb13RvzOSBLWjTwJ+vNh3l8fk76RsZwge3ROHr6cSTfGkN2akXXgitiqIiOP6ncTH16HrjZ1aysc472B7w9pBv1A3cS5nnUNQoR4S6O8aF0qFAIsaF0hu01rvP264dsASI1OXoUiOhLkqSmWvj3RWHmLvmMO4Wxd1DWnH7JZF4WS0UFml+3X2COati2RafToC3lZv6NuPm/s2o739u+M//M4GHv9tBt6aBfHRbL+p5OWCQMVeltdFWf3T93yGfGmOsc/cymn3qNTZmlKrXBPwb2V83NkbR9AmWs/sa4qgujSOBtzC6NM7VWr+glHoOiNZaL7Bv8wzgpbWeXp7CJNRFWY6kZvHCwr0s3XOS8CBvxnZvwvxticSn5RAR7MPkgZGM7xle6sXVxTuPc+9Xf9K+UT0+/WdvgnzljLPcziRD/AYj4E/FGZOOnD5mv25wXm5YPI3A9wk1brAqKjDuci0qKPawv9b2n4HNjG6iTXtDeC8IjJBfDOUgNx8Jp7cuJoXnftnDvhOZ9IgIZMqgFgzr0BCLW/kC4Pd9J5n2+VZahPry2e19CPOvJXe0OqtCmxHsp49D5rG/w/70MchJM/r2u7mDm8X+cC/2sL9GGf3nE7cY88qC0UWzaS8I722EfaOuYL2w6a2uk1AXLqGgsIikzLxKT8CxNiaFyZ9E0yjQiy8m96FRQC3sF18XFRYYN1DFbzIeCZuMvwrAmAGrYRdjUpN6jS+8N8AnxPglUcdIqAthtzkujds+2kyQr5UvJ/elaXAVe5GI6nEm6e+Aj98MJ3cZE6ScT7mBb9i5N3+5exjNPLrIuE6g7c/PLisyllk8ILgFhLSGkFbGWD/e5ettZTYJdSGK2R6fzs1zN+HjYeGLyX1oESaDXTmF/Gz7fQBJf98PcPZR7GawIpsR9spi/HRzs78uvsxiNPmkHzVC/i++YfaAtz9C7YEf1Nzo119LSKgLcZ49x05z04cbUUrxxeQ+tG1YwcmyhWsoyDeaelIPGj19Ug5C6iHjeVbS39spN2NgtOCW9rN7+8/glvbAr9mL7xLqQlxETFImN36wkVxbEfcPbc2NfSPwdK977bOiBDnpkHbIuFEr7ZDR3TP1kPG8+Lj3xQM/MAI8/f9+ePgZwx57+Bs/zy7zN8YPquQvAwl1IUpwNDWbx+bvYG1MKk0CvXng8taM7RFe7l41og7S2rjLN9Ue9MUDPyPBmP+2IKfs/fS/F654vlIlSKgLUYY1B1N49dd97EjIoHV9Px6+si1XdGjguAHBRN1SWGCMi59/xgj5vDOQ/9dP+7KGXaBZv0rtXkJdiHLQWrNk1wleW7qf2OQsujUN5NHh7ejXsoqTXddCWXkFvL50P+sPpfLF5D61ZyYqUS5lhXotmXpGCHMppRjRuRFLHxjEK+M6c/J0LhPf38BNH25kZ0Itml+1ilYfTObKt1bx0do4DpzM5I1lB8wuSTiYnKkLcRG5tkI+W3+Ed1fGkJ5tY1SXRtzctxldmwZWadTH07k2Vh1I5rc9J1l9MIWWYX48OKxNtf9FkJFt4/mFe/huSwItwnx5ZVwXFu44zqfr41h430DaN6pXrZ8vHEeaX4SogtO5Nt5fFcuHaw6TnV+Ih7sb3ZoG0icymD6RIfRoFljmxB7xadks33uS5fuS2BCbiq1QE+Rj5ZLWYWw6nMrJ03kMaBXCv65oS4+IIIcfw5Jdx3nyp92kZeUzdVAL7hvaGi+rhfTsfAa/vpIOjerxxeQ+cg3BSUioC+EAGTk2Nh1OY2NsKpvi0tiVmEGRBnc3RacmAfRpEUyfyGB6NgvG39OdnYkZ/Lb3JMv2nGTfiUwAWob5cnn7BlzeoQE9IoKwuClybYV8vuEI7608RGpWPpe1q89Dw9rQqUk5ZzQqRVJmLk//tJvFu07QoVE9Xh3f5YL9frIujqcX7Gb2TT25sqNMluEMJNSFqAaZuTa2HDnFpsNpbDqcxvaEdGyFGqUgwNtKerYNNwVRzYMZ1r4BQ9vXL/Xu1ay8Aj5eF8ecVbFk5NgY0akhDw5rQ5sGFb8xSmvNvK2J/N8ve8ixFXL/0NZMGdQCq+XCS2gFhUWM+N9q8guLWPrgIOmr7wQk1IWoATn5hfwZb4R8wqkc+rcMYUjb+hUe6vd0ro0PVh9m7prDZOUXcHXXxtx/eRsiQ31LfV9+QRFn8go4eTqXFxftZfXBFKKaBfHyuC60ql/6UAirDiRz89xNTB/RjmmXtqxQvaLmSagL4YTSsvKZveoQn6yLw1aoGdquPlaLG2fyCjiTV0BWsZ9ZeYXkF/49homPh4VHh7fjpr7NcCvnjVS3f7yZjYfTWPHwYBmauJaTUBfCiSVl5jJzxSGW7TmJl9UNP093fO0P/2LP/TwtZ59f0iq0wkMUxyaf4cq3VjGuRzgvj+tSTUcjHEFCXQhRLs//socP1x7m53succiFWlE95OYjIUS53Du0NUE+Hjz3yx7MOtkTVSehLoQAjF47/7qiDZsOp7F41wmzy6k2aVn5/L7vpNllVBsJdSHEWdf3iqBdQ39eXLSXXFuh2eU4XE5+IbfM3cQ/P47m2+h4s8upFhLqQoizLG6Kp67qQMKpHD5cc9jschxKa83D329n1zFjNM6nftrFfvuNYa5EQl0IcY7+LUO5smMD3l0Rw8nTuWaX4zBv/x7Dwh3HeXR4O764ow9+nlbu/GILWXkFZpfmUBLqQogL/GdkBwoKNa8u2W92KQ6xeOdx3lh2gLHdmzB1UAvq+3sxY2I34lKyeHz+Tpe6MCyhLoS4QESID/+8JJJ5WxPYHp9udjlVsisxg4e+3U73iEBeHNv57MBl/VuG8uDlbfhp2zG+2uQ67esS6kKIi7rnslaE+nk6dRfHpMxcpnwaTaCPldk39bxg2OS7h7RiYOtQnvl5N7sSXWPcfLn5SAhRom83x/PveTsY0jaMIF8PPCxueLi7YbUYDw+LOue1p9WNel5WAryt1PO2//Ryp5639aIDilWnvIJCJs7ZwN7jmXw3rV+JN1Slnslj5IzVeFst/HzvJfh7WWu0zooq6+aj0geCFkLUaeN7hrPxcBp/Hj3FwaQz5BcUYSsswlaoyS8oOmfMmbL4eFiKBb477RrWo3/LEPq1DCHQp2IDn5VFa81jP+xk69F0Zt7Yo9Q7ZEP8PHl7Yg8mvr+B6fN28s4N3Z16bHkJdSFEidzcFP+d0LXE9VprCoo0tsIi8guKyLUVcTrXxukcGxk5NvvzAuN5sWWnsm3M25rAZxuOoBR0bFyPAS1D6d8qlF7Ng8qceKQs76+O5YetiTx4eRtGdm5U5va9I4N5+Iq2vLJkH73XB3NL/+ZV+nwzSagLISpNKYXVorBa3PjrZLthgFe53msrLGJ7fDprY1JZeyiFuWsPM3tVLFaLontEEANahjKgVQhdmwZWqOnm930neWnxPkZ1acR9Q1uV+31TB7Vg0+FUnl+4h+4RgXQJDyz3e2uTcrWpK6WGA/8DLMAHWuuXL7LNBOAZQAPbtdY3lLZPaVMXQhSXnV/A5rhTrItJYe2hFHYfO43W4G210LlJAN0iAukaHki3iEAaB3hdtInkwMlMxs5cR/NQH76b2h9vj4pN+nEqK59RM1bj5qZYeO9AAnxqX/t6lUdpVEpZgAPAMCAB2AxM1FrvKbZNa+Bb4DKt9SmlVH2tdVJp+5VQF0KU5lRWPhtiU9lon1lqd+Lps234Yf6edA0PpLs96Ls0DaCgUHPNu2vJsRWy4J4BNAqo2PDDf9l69BQTZq1nSLv6zLmpZ61rX3fEhdLeQIzWOta+w6+Bq4E9xba5A3hXa30KoKxAF0KIsgT5ejCicyNG2NvE8wuK2Hv8NNsT0tl2NJ1t8en8ttcYmEsp8Pd0J7egiG+m9K10oAP0iAhi+oh2PL9wLx+uOczkgS0ccjw1pTyh3gQo3jM/Aehz3jZtAJRSazGaaJ7RWi9xSIVCCAF4uLvRtWkgXZsGcnM/Y1lGto3tCelsj09nZ2IG13ZvQveIoCp/1u2XRLLpcBovL95H40BvhndsWO5ZpMzmqAul7kBrYDAQDqxSSnXWWp9zK5pSagowBSAiIsJBHy2EqKsCfKwMahPGoDZhDt2vUorXxndl3Kx13PXFVto08GPKoJaM6doYD/fafc9meapLBJoWex1uX1ZcArBAa23TWh/GaINvff6OtNZztNZRWuuosDDHfglCCOFIAT5WFt8/kDcmdMVNKR7+bjuDXl3BnFWHyMy1mV1eicoT6puB1kqpSKWUB3A9sOC8bX7EOEtHKRWK0RwT68A6hRCixlktboztEc7i+wfy8W29iAz15cVF++j/0u+8vHgfSbVwFMsym1+01gVKqXuAXzHay+dqrXcrpZ4DorXWC+zrrlBK7QEKgUe01qnVWbgQQtQUpRSD29ZncNv67EhIZ/aqWOasOsTcNYe5tnsT7hjUglb1/cwuE5CxX4QQolKOpGbxwerDfBsdT15BEYPbhnF5+wYMah1GRIhPtX1ulfupVxcJdSGEK0g9k8cn648wb0sCiek5ADQL8WFg61AGtg6jX8sQ6jlwkDAJdSGEqAFaaw6nZLH6YAqrDyaz7lAq2fmFWNwUPSICGdg6jIGtQ+kSHoilCt0jJdSFEMIE+QVFbD16itUHk1l9MIWdiRloDQHeVu4Z0oo7BlXupiYZelcIIUzg4e5G3xYh9G0RwiNXQlpWPmtiUlh9IJkG5Rz0rDIk1IUQogYE+3owpmtjxnRtXK2fU7tvjRJCCFEhEupCCOFCJNSFEMKFSKgLIYQLkVAXQggXIqEuhBAuREJdCCFciIS6EEK4ENOGCVBKJQNHKvn2UCDFgeXUBq52TK52POB6x+RqxwOud0wXO55mWusSZxkyLdSrQikVXdrYB87I1Y7J1Y4HXO+YXO14wPWOqTLHI80vQgjhQiTUhRDChThrqM8xu4Bq4GrH5GrHA653TK52POB6x1Th43HKNnUhhBAX56xn6kIIIS5CQl0IIVyI04W6Umq4Umq/UipGKTXd7HocQSkVp5TaqZTappRyujn+lFJzlVJJSqldxZYFK6WWKaUO2n8GmVljRZVwTM8opRLt39M2pdRIM2usCKVUU6XUCqXUHqXUbqXU/fblTvk9lXI8zvwdeSmlNimlttuP6Vn78kil1EZ75n2jlPIodT/O1KaulLIAB4BhQAKwGZiotd5jamFVpJSKA6K01k5504RSahBwBvhUa93JvuxVIE1r/bL9l2+Q1vpRM+usiBKO6RngjNb6dTNrqwylVCOgkdZ6q1LKH9gCXAPcihN+T6UczwSc9ztSgK/W+oxSygqsAe4HHgJ+0Fp/rZSaBWzXWr9X0n6c7Uy9NxCjtY7VWucDXwNXm1xTnae1XgWknbf4auAT+/NPMP6HcxolHJPT0lof11pvtT/PBPYCTXDS76mU43Fa2nDG/tJqf2jgMuB7+/IyvyNnC/UmQHyx1wk4+Rdpp4GlSqktSqkpZhfjIA201sftz08ADcwsxoHuUUrtsDfPOEVTxfmUUs2B7sBGXOB7Ou94wIm/I6WURSm1DUgClgGHgHStdYF9kzIzz9lC3VVdorXuAYwA7rb/6e8ytNHG5zztfCV7D2gJdAOOA/81t5yKU0r5AfOAB7TWp4uvc8bv6SLH49Tfkda6UGvdDQjHaJloV9F9OFuoJwJNi70Oty9zalrrRPvPJGA+xpfp7E7a2z3/av9MMrmeKtNan7T/T1cEvI+TfU/2dtp5wBda6x/si532e7rY8Tj7d/QXrXU6sALoBwQqpdztq8rMPGcL9c1Aa/vVYA/gemCByTVViVLK136hB6WUL3AFsKv0dzmFBcAt9ue3AD+ZWItD/BV+dtfiRN+T/SLch8BerfUbxVY55fdU0vE4+XcUppQKtD/3xugQshcj3MfbNyvzO3Kq3i8A9i5KbwEWYK7W+gWTS6oSpVQLjLNzAHfgS2c7JqXUV8BgjGFCTwJPAz8C3wIRGEMsT9BaO82FxxKOaTDGn/UaiAOmFmuPrtWUUpcAq4GdQJF98eMY7dBO9z2VcjwTcd7vqAvGhVALxgn3t1rr5+wZ8TUQDPwJTNJa55W4H2cLdSGEECVztuYXIYQQpZBQF0IIFyKhLoQQLkRCXQghXIiEuhBCuBAJdSGEcCES6kII4UL+HzFLQtyc2l7DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()                                       \n",
    "plt.show()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7197604775428772\n"
     ]
    }
   ],
   "source": [
    "#가전제품 f1-score: 0.7819220343082984\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 화장품"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_화장품_resampled, Y_화장품_resampled, test_size=0.3, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_3 (Masking)          (None, 5000, 19)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                21504     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 24,163\n",
      "Trainable params: 24,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#masking layer 추가(https://stackoverflow.com/questions/49670832/keras-lstm-with-masking-layer-for-variable-length-inputs)\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(64,input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation= 'relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr= 0.001, rho = 0.9), metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1732 samples, validate on 743 samples\n",
      "Epoch 1/50\n",
      " - 27s - loss: 1.1026 - acc: 0.3458 - val_loss: 1.0818 - val_acc: 0.4576\n",
      "Epoch 2/50\n",
      " - 27s - loss: 1.0733 - acc: 0.4353 - val_loss: 1.0429 - val_acc: 0.5316\n",
      "Epoch 3/50\n",
      " - 27s - loss: 1.0409 - acc: 0.4925 - val_loss: 1.0125 - val_acc: 0.5532\n",
      "Epoch 4/50\n",
      " - 27s - loss: 1.0158 - acc: 0.5300 - val_loss: 0.9910 - val_acc: 0.5505\n",
      "Epoch 5/50\n",
      " - 26s - loss: 0.9908 - acc: 0.5543 - val_loss: 0.9674 - val_acc: 0.5734\n",
      "Epoch 6/50\n",
      " - 27s - loss: 0.9755 - acc: 0.5554 - val_loss: 0.9484 - val_acc: 0.5774\n",
      "Epoch 7/50\n",
      " - 27s - loss: 0.9510 - acc: 0.5716 - val_loss: 0.9300 - val_acc: 0.5841\n",
      "Epoch 8/50\n",
      " - 27s - loss: 0.9399 - acc: 0.5779 - val_loss: 0.9183 - val_acc: 0.5908\n",
      "Epoch 9/50\n",
      " - 26s - loss: 0.9288 - acc: 0.5889 - val_loss: 0.8980 - val_acc: 0.5949\n",
      "Epoch 10/50\n",
      " - 27s - loss: 0.9128 - acc: 0.5930 - val_loss: 0.8819 - val_acc: 0.6137\n",
      "Epoch 11/50\n",
      " - 27s - loss: 0.8934 - acc: 0.5872 - val_loss: 0.8783 - val_acc: 0.6178\n",
      "Epoch 12/50\n",
      " - 27s - loss: 0.8926 - acc: 0.5872 - val_loss: 0.8616 - val_acc: 0.6151\n",
      "Epoch 13/50\n",
      " - 27s - loss: 0.8737 - acc: 0.6085 - val_loss: 0.8553 - val_acc: 0.6151\n",
      "Epoch 14/50\n",
      " - 26s - loss: 0.8659 - acc: 0.6033 - val_loss: 0.8454 - val_acc: 0.6501\n",
      "Epoch 15/50\n",
      " - 27s - loss: 0.8553 - acc: 0.6166 - val_loss: 0.8350 - val_acc: 0.6433\n",
      "Epoch 16/50\n",
      " - 27s - loss: 0.8412 - acc: 0.6103 - val_loss: 0.8296 - val_acc: 0.6474\n",
      "Epoch 17/50\n",
      " - 27s - loss: 0.8328 - acc: 0.6120 - val_loss: 0.8211 - val_acc: 0.6433\n",
      "Epoch 18/50\n",
      " - 27s - loss: 0.8291 - acc: 0.6143 - val_loss: 0.8179 - val_acc: 0.6487\n",
      "Epoch 19/50\n",
      " - 27s - loss: 0.8226 - acc: 0.6212 - val_loss: 0.8223 - val_acc: 0.6433\n",
      "Epoch 20/50\n",
      " - 26s - loss: 0.8209 - acc: 0.6184 - val_loss: 0.8079 - val_acc: 0.6447\n",
      "Epoch 21/50\n",
      " - 27s - loss: 0.8080 - acc: 0.6143 - val_loss: 0.8067 - val_acc: 0.6420\n",
      "Epoch 22/50\n",
      " - 27s - loss: 0.8017 - acc: 0.6270 - val_loss: 0.8140 - val_acc: 0.6406\n",
      "Epoch 23/50\n",
      " - 27s - loss: 0.8058 - acc: 0.6299 - val_loss: 0.7999 - val_acc: 0.6474\n",
      "Epoch 24/50\n",
      " - 27s - loss: 0.7990 - acc: 0.6236 - val_loss: 0.7990 - val_acc: 0.6514\n",
      "Epoch 25/50\n",
      " - 27s - loss: 0.7883 - acc: 0.6230 - val_loss: 0.8018 - val_acc: 0.6528\n",
      "Epoch 26/50\n",
      " - 27s - loss: 0.7831 - acc: 0.6276 - val_loss: 0.8211 - val_acc: 0.6447\n",
      "Epoch 27/50\n",
      " - 27s - loss: 0.7840 - acc: 0.6345 - val_loss: 0.8031 - val_acc: 0.6649\n",
      "Epoch 28/50\n",
      " - 27s - loss: 0.7833 - acc: 0.6363 - val_loss: 0.7921 - val_acc: 0.6703\n",
      "Epoch 29/50\n",
      " - 27s - loss: 0.7762 - acc: 0.6282 - val_loss: 0.7935 - val_acc: 0.6649\n",
      "Epoch 30/50\n",
      " - 27s - loss: 0.7671 - acc: 0.6403 - val_loss: 0.8617 - val_acc: 0.6231\n",
      "Epoch 31/50\n",
      " - 27s - loss: 0.7928 - acc: 0.6299 - val_loss: 0.7911 - val_acc: 0.6581\n",
      "Epoch 32/50\n",
      " - 27s - loss: 0.7601 - acc: 0.6461 - val_loss: 0.7921 - val_acc: 0.6635\n",
      "Epoch 33/50\n",
      " - 27s - loss: 0.7603 - acc: 0.6357 - val_loss: 0.7894 - val_acc: 0.6676\n",
      "Epoch 34/50\n",
      " - 27s - loss: 0.7550 - acc: 0.6495 - val_loss: 0.7891 - val_acc: 0.6649\n",
      "Epoch 35/50\n",
      " - 27s - loss: 0.7507 - acc: 0.6415 - val_loss: 0.7944 - val_acc: 0.6649\n",
      "Epoch 36/50\n",
      " - 27s - loss: 0.7476 - acc: 0.6524 - val_loss: 0.7924 - val_acc: 0.6622\n",
      "Epoch 37/50\n",
      " - 27s - loss: 0.7437 - acc: 0.6559 - val_loss: 0.7925 - val_acc: 0.6703\n",
      "Epoch 38/50\n",
      " - 27s - loss: 0.7595 - acc: 0.6420 - val_loss: 0.7901 - val_acc: 0.6662\n",
      "Epoch 39/50\n",
      " - 27s - loss: 0.7315 - acc: 0.6559 - val_loss: 0.7922 - val_acc: 0.6595\n",
      "Epoch 40/50\n",
      " - 27s - loss: 0.7479 - acc: 0.6397 - val_loss: 0.7931 - val_acc: 0.6743\n",
      "Epoch 41/50\n",
      " - 27s - loss: 0.7361 - acc: 0.6645 - val_loss: 0.7907 - val_acc: 0.6635\n",
      "Epoch 42/50\n",
      " - 27s - loss: 0.7228 - acc: 0.6669 - val_loss: 0.7872 - val_acc: 0.6608\n",
      "Epoch 43/50\n",
      " - 27s - loss: 0.7370 - acc: 0.6628 - val_loss: 0.7979 - val_acc: 0.6608\n",
      "Epoch 44/50\n",
      " - 27s - loss: 0.7417 - acc: 0.6484 - val_loss: 0.7988 - val_acc: 0.6568\n",
      "Epoch 45/50\n",
      " - 27s - loss: 0.7283 - acc: 0.6536 - val_loss: 0.7878 - val_acc: 0.6703\n",
      "Epoch 46/50\n",
      " - 27s - loss: 0.7122 - acc: 0.6749 - val_loss: 0.7891 - val_acc: 0.6581\n",
      "Epoch 47/50\n",
      " - 27s - loss: 0.7193 - acc: 0.6796 - val_loss: 0.8049 - val_acc: 0.6541\n",
      "Epoch 48/50\n",
      " - 27s - loss: 0.7572 - acc: 0.6455 - val_loss: 0.7949 - val_acc: 0.6676\n",
      "Epoch 49/50\n",
      " - 27s - loss: 0.7300 - acc: 0.6669 - val_loss: 0.7893 - val_acc: 0.6649\n",
      "Epoch 50/50\n",
      " - 27s - loss: 0.7086 - acc: 0.6749 - val_loss: 0.7908 - val_acc: 0.6649\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=500, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
